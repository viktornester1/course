{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viktornester1/course/blob/main/00_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TotNJ31jsFYX"
      },
      "source": [
        "---\n",
        "\n",
        "# **00_PyTorch**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpmtIxdesFib",
        "outputId": "104ac92d-20b2-43ff-c5b9-80abb5d89d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJiMg-uLHhL3"
      },
      "source": [
        "---\n",
        "\n",
        "###**Creating tensors**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlHFzYrmHJ5A",
        "outputId": "c811af3f-ca0c-4b18-e676-b1c3d9d67ead"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "#scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqQjTR5vKXoV",
        "outputId": "7b78eab3-9488-40fe-e860-87677670ab57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXsDpqd2Kv6S",
        "outputId": "09a491db-5c57-4b5c-c1c6-a7789eab51b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBlTCyBCK-4T",
        "outputId": "c02b6b15-3754-40d8-ffbc-9fff1426935b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alqeh3-9LGmj",
        "outputId": "6616e281-f0e9-483a-9dc8-5c1715141378"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqIoZ0ScK-oz",
        "outputId": "400a75af-afd2-4d26-b65c-559a7d650d53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFAjabDUK-Yc",
        "outputId": "f2472705-113c-4bf8-c192-ac0fe20df3b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ2JXX67MQ_L",
        "outputId": "082b8c4c-6b6c-4958-b79c-e0b9cc9e808a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAu9W4NpM5cY",
        "outputId": "861b394e-203a-42d1-b136-a1ec5d5f6801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kghFMUH7NTGH",
        "outputId": "49c54b99-9485-41a6-c4db-0d53d946eace"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flNQm462Nd6o",
        "outputId": "e90035e4-f9cb-4ad7-c135-a4214fd93d82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtGS4oWYN7Ua",
        "outputId": "aa260acf-5acf-46c5-8a59-762cfbee3903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [8, 9, 0]],\n",
            "\n",
            "        [[5, 5, 5],\n",
            "         [5, 5, 5],\n",
            "         [5, 5, 6]]])\n"
          ]
        }
      ],
      "source": [
        "#TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [8, 9, 0]],\n",
        "\n",
        "                       [[5, 5, 5],\n",
        "                        [5, 5, 5],\n",
        "                        [5, 5, 6]]])\n",
        "\n",
        "TENSOR\n",
        "print(TENSOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZHObOkwRiqD",
        "outputId": "0318c79f-4f1f-45c6-c224-03b4a4a8f921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoIMan_WRj5t",
        "outputId": "fc1323f7-8e12-43c0-c308-af25e7a92e39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGvJ8C8vRk26",
        "outputId": "59f02268-eefa-40e5-9904-f3d35cbc987e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5, 5, 5],\n",
              "        [5, 5, 5],\n",
              "        [5, 5, 6]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plU0uw6MjgPp"
      },
      "source": [
        "---\n",
        "\n",
        "#Random tensors\n",
        "\n",
        "---\n",
        "`A machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD-wVu7pjuPK",
        "outputId": "d3b6605b-8764-4dde-9181-68e8e28141c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.7293, 0.6724, 0.2981, 0.5592, 0.2141, 0.0991, 0.4463, 0.4304,\n",
              "          0.1555, 0.7958],\n",
              "         [0.1970, 0.3081, 0.7376, 0.8495, 0.9723, 0.9843, 0.0459, 0.8662,\n",
              "          0.7370, 0.2289],\n",
              "         [0.8603, 0.5526, 0.1970, 0.9990, 0.7739, 0.5564, 0.3646, 0.3453,\n",
              "          0.8989, 0.7453],\n",
              "         [0.7747, 0.1006, 0.4461, 0.9403, 0.5834, 0.6367, 0.7537, 0.8502,\n",
              "          0.9595, 0.5554],\n",
              "         [0.6303, 0.0653, 0.6917, 0.5967, 0.0876, 0.5384, 0.0687, 0.8586,\n",
              "          0.4172, 0.4016],\n",
              "         [0.7907, 0.6000, 0.2392, 0.4275, 0.5828, 0.7875, 0.5864, 0.9208,\n",
              "          0.7859, 0.7845],\n",
              "         [0.5857, 0.8969, 0.9922, 0.0106, 0.5540, 0.9141, 0.0176, 0.9519,\n",
              "          0.0281, 0.4391],\n",
              "         [0.6420, 0.9379, 0.5290, 0.3949, 0.8524, 0.2288, 0.8321, 0.5734,\n",
              "          0.2991, 0.3066],\n",
              "         [0.1813, 0.9694, 0.5742, 0.4242, 0.7605, 0.9581, 0.2112, 0.4039,\n",
              "          0.7851, 0.2491],\n",
              "         [0.1641, 0.4254, 0.1833, 0.1246, 0.7067, 0.9601, 0.8141, 0.5698,\n",
              "          0.7365, 0.7812]],\n",
              "\n",
              "        [[0.9519, 0.6209, 0.2861, 0.4555, 0.4864, 0.7736, 0.9622, 0.5950,\n",
              "          0.5490, 0.2674],\n",
              "         [0.6312, 0.7179, 0.4423, 0.0824, 0.8266, 0.1455, 0.4360, 0.7130,\n",
              "          0.3123, 0.9285],\n",
              "         [0.6392, 0.5915, 0.9158, 0.8867, 0.9025, 0.7584, 0.6939, 0.5060,\n",
              "          0.6714, 0.2558],\n",
              "         [0.6935, 0.1145, 0.9836, 0.9478, 0.3484, 0.4367, 0.4297, 0.4884,\n",
              "          0.7706, 0.3587],\n",
              "         [0.7793, 0.9304, 0.6524, 0.7244, 0.9489, 0.4192, 0.0817, 0.0949,\n",
              "          0.3406, 0.9423],\n",
              "         [0.1703, 0.7881, 0.0311, 0.2260, 0.6609, 0.4727, 0.9306, 0.7815,\n",
              "          0.3738, 0.1079],\n",
              "         [0.3140, 0.6110, 0.6457, 0.9855, 0.9798, 0.6177, 0.3197, 0.9959,\n",
              "          0.5249, 0.0147],\n",
              "         [0.0198, 0.9338, 0.6763, 0.6653, 0.3489, 0.5082, 0.8685, 0.0563,\n",
              "          0.7752, 0.4944],\n",
              "         [0.3871, 0.3941, 0.5161, 0.1558, 0.9246, 0.0510, 0.7708, 0.4234,\n",
              "          0.4192, 0.0913],\n",
              "         [0.0663, 0.9500, 0.3849, 0.7079, 0.5657, 0.5941, 0.2052, 0.6787,\n",
              "          0.1711, 0.2247]]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# random tensor of size (3, 4)\n",
        "# random_tensor = torch.rand(3, 4)\n",
        "random_tensor = torch.rand(2, 10, 10)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPXGsggRkv4",
        "outputId": "53557710-a7d4-4ea7-c2f4-33c3d4a4e461"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 10, 10]), 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.shape, random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3q2i0HaRkMw",
        "outputId": "f1284588-efa6-469b-e714-41546b8338a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 224, 224]), 'number of dimentions: ', 3)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with similiar shape to an image tensor\n",
        "random_image_tensor = torch.rand(size=(3, 224, 224)) # height, width, color channels (R, G, B); size=() is an optional synthax\n",
        "random_image_tensor.shape, \"number of dimentions: \" ,random_image_tensor.ndim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTl2gJ2Ws03F"
      },
      "source": [
        "---\n",
        "\n",
        "#**Zeros** and ones\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeuFZAiQsdo2",
        "outputId": "b96d036a-2574-4e12-b7c0-4ed2e7812044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " tensor([[0.4991, 0.3361, 0.5406, 0.4902],\n",
              "         [0.3824, 0.9143, 0.3540, 0.7548],\n",
              "         [0.4977, 0.3802, 0.8139, 0.7919],\n",
              "         [0.3253, 0.6329, 0.3946, 0.2154]]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of zeros\n",
        "zeros = torch.zeros(4, 4)\n",
        "x = torch.rand(4,4)\n",
        "zeros, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT0w9ay_sRuv",
        "outputId": "8c4bc42a-8be0-4d92-ccc2-186420d9c87b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ibf_cVtabb",
        "outputId": "8a557ce6-e65d-4f4a-dce8-5360e74d4fc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of ones\n",
        "ones = torch.ones(4, 4)\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHbaVjx3taQ2",
        "outputId": "21f1be17-be02-4c3e-cfe4-f20cc4304bf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi15hHdmv5DC"
      },
      "source": [
        "---\n",
        "\n",
        "#**Create a range of tensors and tensors-like**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3cy4mAtxgep"
      },
      "source": [
        "# Use 'torch.arange()' instead of old 'torch.range()'\n",
        "torch.range(0, 10)  # bad\n",
        "torch.arange(0, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgQxa9wmxgWQ",
        "outputId": "6ada0e45-d7ee-4e8d-b29b-514624192429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# one_to_ten = torch.arange(start=0, end=1000, step=33)\n",
        "# one_to_ten = torch.arange(0, 1000, 10)\n",
        "one_to_ten = torch.arange(start=0, end=11, step=1)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k9y9lZ4xgTo",
        "outputId": "f28b2e65-7825-451d-ae73-d7072882c677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating tensors like\n",
        "# ten_zeros = torch.zeros_like(input = one_to_ten)\n",
        "ten_zeros = torch.zeros_like(one_to_ten)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0eQKk3-lhE7"
      },
      "source": [
        "#**Tensor datatypes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tvC91FIsZVi"
      },
      "source": [
        "**Note:** Tensor datatypes is one of 3 big errors you'll run into with Pytorch DL:\n",
        "\n",
        "\n",
        "1.   Tensors not right datatype\n",
        "2.   Tensors not right shape\n",
        "3.   Tensor not on right device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAS9lLkCmQmV",
        "outputId": "31ff966e-d759-4c3c-87a0-9beb331a2824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datatype_tensor = torch.tensor([3., 6., 9.],\n",
        "                               dtype=None, # what datatype is in tensor # точність залежить від кількості біт: більше біт = точніше але повільніше, менше = навпаки. 32 - стандарт, одиниця точності\n",
        "                               device=None, # What device is your tensor on\n",
        "                               requires_grad=False) # Whether or not track gradients with this tensors operations\n",
        "datatype_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7hocf0zmQkE",
        "outputId": "020887f4-8248-405a-d04a-43c7b1987556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datatype_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0LuKPNStdLI",
        "outputId": "dac21d18-4c77-413b-c17d-b6819c65acde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = datatype_tensor.type(torch.float16) # torch.half is fine too\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbUmupAbtdC_",
        "outputId": "8cfca0ed-966e-4383-b53f-5900de1f775f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = float_16_tensor*datatype_tensor\n",
        "x.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELwmIovzvwBw",
        "outputId": "a1eb9907-8fc9-4563-cb1b-08ea3c74a503"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype = torch.int32)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFG4-uMzxIle",
        "outputId": "a9650c70-cabb-4c22-bee8-c16ed1e103c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float16)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor*float_16_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiD4EoUNzLWy"
      },
      "source": [
        "\n",
        "# **Getting information from tensors**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aXuU75_mQhi",
        "outputId": "8f486f9e-50bf-4f85-e52a-4405dc4bd1b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4351, 0.9698, 0.8766, 0.5357],\n",
              "        [0.2411, 0.9338, 0.1303, 0.8154],\n",
              "        [0.1682, 0.1009, 0.1304, 0.7164]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s_tensor = torch.rand(3, 4)\n",
        "s_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NEndlFumQfS",
        "outputId": "9a0ff9fb-70e4-44f1-fc24-84342d8536d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4351, 0.9698, 0.8766, 0.5357],\n",
            "        [0.2411, 0.9338, 0.1303, 0.8154],\n",
            "        [0.1682, 0.1009, 0.1304, 0.7164]])\n",
            "Datatype: torch.float32\n",
            "Shape: torch.float32\n",
            "Device tensor is on: cpu\n"
          ]
        }
      ],
      "source": [
        "print(s_tensor)\n",
        "print(f\"Datatype: {s_tensor.dtype}\")\n",
        "print(f\"Shape: {s_tensor.dtype}\")\n",
        "print(f\"Device tensor is on: {s_tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSZLvbPL1jQI"
      },
      "source": [
        "## **Manipulating tensors (tensor operations)**\n",
        "Tensor operations include:\n",
        "\n",
        "\n",
        "*   Addition\n",
        "*   Substractiom\n",
        "*   Multiplication(element-wise)\n",
        "*   Division\n",
        "*   Matrix multiplication\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvxatIyhmQcy",
        "outputId": "6839b235-029b-4ec0-b3c1-856b2c2a51c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([11, 12, 13]), tensor([10, 20, 30]), tensor([-9, -8, -7]))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tens = torch.tensor([1, 2, 3])\n",
        "tens+10, tens*10, tens-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMLnY5jV4rKS"
      },
      "outputs": [],
      "source": [
        "# Matrix multiplications\n",
        "# Two main ways of mult:\n",
        "# 1)element-wise 2)matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSIiO_6M5fa1",
        "outputId": "ac6a3be2-b37a-4df4-d315-9da02de8c7dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element wise\n",
        "tens*tens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyHQuDOZ5teP",
        "outputId": "0b52f4e3-1ca1-4396-db53-6a8880ab8fe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Matrix multiplication\n",
        "torch.matmul(tens, tens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMjxX-w8oQ_"
      },
      "source": [
        "### One of the common errors is a shape error\n",
        "\n",
        "there are 2 rules in matrix multiplications:\n",
        "\n",
        "\n",
        "1.   inner dimentions must match\n",
        "*   `(3,2) @ (3,2) won't work`\n",
        "*   `(2,3) @ (3,2) will work` - inner dimensions are 3, 3\n",
        "*   `(3 2) @ (2,3) will work` - inner dimensions are 2, 2\n",
        "\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBu91ZYG84nv",
        "outputId": "e7587819-fcae-459d-c09b-39caf31e8aaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tens @ tens # is the same as .matmul amd the same as .mm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVipfb8B84lN",
        "outputId": "d87595d3-61cd-4f4d-e1d0-1dd6482d6a09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B.T) # (this will error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3Qz47y-CF-0",
        "outputId": "c10ea5e7-b748-4b99-a9f6-d0a8659bd5d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7., 10.],\n",
              "        [ 8., 11.],\n",
              "        [ 9., 12.]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTVFSeHm84jI",
        "outputId": "33d6bd74-9190-4e7b-d88b-8e839cdc3d05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7.,  8.,  9.],\n",
              "        [10., 11., 12.]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can use transpose to fix shape mistakes\n",
        "\n",
        "tensor_B.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8GGbYozCF84",
        "outputId": "de3366ff-3652-477a-b604-c95ad2982a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AmHjrXrENHt"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc (aggregation)\n",
        "\n",
        "Now we've seen a few ways to manipulate tensors, let's run through a few ways to aggregate them (go from more values to less values).\n",
        "\n",
        "First we'll create a tensor and then find the max, min, mean and sum of it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "misDREMpCF6t",
        "outputId": "006dcf37-9e6f-4d88-e02c-263d831c6bd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(1, 101, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N03rzoY0CF4e",
        "outputId": "a1619f22-81d2-4f9a-af2a-19f7a8b28505"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(91), tensor(46., dtype=torch.float16))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.min(x), torch.max(x), torch.mean(x.type(torch.float16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUccj1nsrfXx"
      },
      "source": [
        "### Positional min/max\n",
        "\n",
        "You can also find the index of a tensor where the max or minimum occurs with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the [softmax activation function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEJLp5m_rHry",
        "outputId": "12f4db88-e6bc-4673-88e9-aa0cccfe5091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWy6mkV8rHpP",
        "outputId": "f03893cb-12b3-45f8-ffc8-fe6a14c5270f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(9))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# findsng index of min or max value in tensor\n",
        "x.argmin(), x.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0k_WGmdsx5T"
      },
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`torch.Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make the right elements of your tensors are mixing with the right elements of other tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl7OqS1Ush7g",
        "outputId": "5ddc080d-d6ce-4422-e593-f63f9c61cbdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us0qXE57qrKA",
        "outputId": "cd64fa4d-2afa-41b7-c3b0-76889524c90c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add extra dimention\n",
        "x_reshaped = x.reshape(1, 9)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Frxo4Ewt5bz",
        "outputId": "14c54110-52e6-4b6d-9ab2-b60a7e6f2abf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " torch.Size([1, 9]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the view, view shares memory with x\n",
        "z = x.view(1, 9)\n",
        "z, z.shape, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WWtmkmkt5ZQ",
        "outputId": "c1934177-5b3d-4564-f9d2-685b68fd27fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]),\n",
              " torch.Size([3, 3]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "z = x.view(3, 3)\n",
        "z, z.shape, x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBc-UnDQxk7U"
      },
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVzHOaIZxkVm",
        "outputId": "3106de6a-7c17-4759-e2af-1f659272a2df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim = 0)\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeOO-mZVy4uA"
      },
      "source": [
        "How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()` (I remember this as *squeezing* the tensor to only have dimensions over 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB9_rczuxtS7",
        "outputId": "b7a2ebd9-de2d-4763-9ed9-ef50e0b9187b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 9])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xDwHPVJxkTR",
        "outputId": "8f72cc5c-9555-4fea-a3c6-eb8a4ee6f3bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_reshaped.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rHgj_EqxkQd",
        "outputId": "41295c91-bf85-4b92-931b-454fbc48f20f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([9])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_reshaped.squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izmSPx9yxj3E",
        "outputId": "cc3d93f4-150d-451d-e30e-051895756054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0BMrQb-0Ir3"
      },
      "source": [
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsM5NAE3xjrO",
        "outputId": "03eaaa20-b952-4f16-f4fa-f841a8c419a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "New shape: torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLcFSQrI1gJs"
      },
      "source": [
        "You can also rearrange the order of values with `torch.permute(input, dims)`, where the `input` gets turned into a *view* with new `dims`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpyxHainxjok",
        "outputId": "e724b971-b7d4-43e4-89a7-409f49533517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 3])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3, 5)\n",
        "x.size()\n",
        "torch.permute(x, (2, 0, 1)).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0sCDDSZ1qq1",
        "outputId": "c30cce5c-2b03-4553-c475-95a7d816d11d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3)) # height, width, color_channel\n",
        "\n",
        "# Permute original tensor to rearrange the axis (or dimension) order\n",
        "x_permuted = x_original.permute(2, 0, 1)\n",
        "x_original.shape, x_permuted.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5yvxub91qmF",
        "outputId": "9a136cac-98ae-4e42-c89c-4627f5cf91f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.6339, 0.5267, 0.5606],\n",
              "         [0.6827, 0.3277, 0.3905],\n",
              "         [0.4641, 0.5173, 0.0919],\n",
              "         ...,\n",
              "         [0.6064, 0.6262, 0.9009],\n",
              "         [0.6127, 0.4671, 0.2997],\n",
              "         [0.4400, 0.5204, 0.5069]],\n",
              "\n",
              "        [[0.5895, 0.1052, 0.9953],\n",
              "         [0.8085, 0.3545, 0.5637],\n",
              "         [0.9663, 0.7189, 0.7531],\n",
              "         ...,\n",
              "         [0.9004, 0.1623, 0.9257],\n",
              "         [0.3154, 0.6617, 0.5909],\n",
              "         [0.6081, 0.1028, 0.3637]],\n",
              "\n",
              "        [[0.3819, 0.2123, 0.3473],\n",
              "         [0.2129, 0.4798, 0.7348],\n",
              "         [0.8358, 0.4971, 0.2050],\n",
              "         ...,\n",
              "         [0.5641, 0.3184, 0.4581],\n",
              "         [0.6640, 0.5471, 0.2268],\n",
              "         [0.4445, 0.6734, 0.9068]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0534, 0.8430, 0.5550],\n",
              "         [0.4000, 0.9554, 0.4332],\n",
              "         [0.4674, 0.7439, 0.8959],\n",
              "         ...,\n",
              "         [0.4797, 0.3697, 0.2710],\n",
              "         [0.6301, 0.1923, 0.6235],\n",
              "         [0.2648, 0.0409, 0.2479]],\n",
              "\n",
              "        [[0.1475, 0.4034, 0.6979],\n",
              "         [0.6604, 0.0693, 0.5984],\n",
              "         [0.9520, 0.8959, 0.2293],\n",
              "         ...,\n",
              "         [0.9306, 0.2703, 0.4918],\n",
              "         [0.6179, 0.9876, 0.9038],\n",
              "         [0.8999, 0.1637, 0.2995]],\n",
              "\n",
              "        [[0.8494, 0.4227, 0.3466],\n",
              "         [0.8498, 0.0483, 0.7501],\n",
              "         [0.2377, 0.4910, 0.9268],\n",
              "         ...,\n",
              "         [0.9635, 0.1769, 0.1483],\n",
              "         [0.4546, 0.9057, 0.9355],\n",
              "         [0.3589, 0.7663, 0.1368]]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original[:,:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBI-hhft5NNN"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "To do so, you can use indexing.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy arrays, indexing in PyTorch with tensors is very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ynvcL7j1qje",
        "outputId": "cf39c222-cd28-4208-d676-13d3ccf56b04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQsNN2fR9BOn",
        "outputId": "8e907939-1a8b-466f-fdae-cb49d04a7148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQRzeqa9BMS",
        "outputId": "21b971fc-c0e4-4ac6-8075-aa41f3ece24a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0, 0] # can do it like that x[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv-v7rNI9BJ3",
        "outputId": "55b5be2e-455a-4822-9534-1e551bc6f787"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Let's index on the most inner bracket(last dim)\n",
        "x[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmipYrD097u7",
        "outputId": "d5fb037d-4c83-47f7-96a9-2fcfc07c9a7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0][2][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oMyrjQz97sj",
        "outputId": "d537807d-cb40-4ff4-9bae-ad11b63db16c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0,0,1] # \"0\" is oth dimension, second \"0\" is first dimension, 1 is a second dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NDyl5_a-nR6"
      },
      "source": [
        "You can also use \":\" to select all of target dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VtfyjlG-mdx",
        "outputId": "6ae98b9a-8366-4988-ec0b-1c20db188f63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP_ZyEyx1qhB",
        "outputId": "ee89a1d9-1311-439e-cd10-eeffdd9bd1da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZwFLpxY1qeZ",
        "outputId": "aa5d03c5-3f15-414c-b94f-e1f447d68a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmj1nuI8Ayum",
        "outputId": "f8360533-68a6-4ab1-d4b0-0bb9e794d166"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZtjkUlkAyqm",
        "outputId": "866d9ec3-8d35-4619-8683-a1911acec983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXi3rxwB03t"
      },
      "source": [
        "*0 is removing brackets and gives elements within, \":\"  outputs all elements in that dim*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pzLMFbXAynq",
        "outputId": "46c5fac3-82c2-402c-a095-1e80a3e2c51d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([9])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:, 2, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb_ZkZkEAyk1",
        "outputId": "4dd715a0-82e6-4f2b-a11c-d8abb1d66b5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:, :, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwABmL_WCubM"
      },
      "source": [
        "---\n",
        "\n",
        "## PyTorch tensors & NumPy\n",
        "\n",
        "---\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.  \n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
        "\n",
        "Let's try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWA3BPjfAyiQ",
        "outputId": "dd5bedc5-f53d-40b2-edcc-c8a81c9c72ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1YOayDTCpi_",
        "outputId": "2029e2cf-cd20-43da-f1a7-84914ee13c1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IKmCEPYEGRm"
      },
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
        "\n",
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmzhCGQoCpgM",
        "outputId": "b3cf3dae-e18f-4c84-bed0-8dd4a4effa32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_-HoTmICpVH",
        "outputId": "9f7758c5-5828-44f1-a37c-b1e390df6eab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_y76Bh6CpTl",
        "outputId": "b9f94287-b659-4428-e002-baf522818ece"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numpy_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V1XCPtPCpPK",
        "outputId": "abc8cb8d-2f6b-40dd-ad51-70a3d6acf701"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the tensor, what happens to `numpy_tensor`?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrjdFyk3Gbzh"
      },
      "source": [
        "## Reproducibility (trying to take the random out of random)\n",
        "\n",
        "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
        "\n",
        "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
        "\n",
        "How does this relate to neural networks and deep learning then?\n",
        "\n",
        "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "``start with random numbers -> tensor operations -> try to make better (again and again and again)``\n",
        "\n",
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where **reproducibility** comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4hLMxjFPsU",
        "outputId": "3f47a331-b47f-412f-b90d-67185e8d1cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor A:\n",
            "tensor([[0.4944, 0.8863, 0.0841, 0.8174],\n",
            "        [0.4589, 0.7530, 0.4716, 0.1362],\n",
            "        [0.9638, 0.3067, 0.8691, 0.0020]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.4244, 0.9517, 0.4942, 0.1069],\n",
            "        [0.9151, 0.3246, 0.2309, 0.4460],\n",
            "        [0.6235, 0.7070, 0.8879, 0.1602]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OADinyzNuKsc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlfsPwCXHeyp"
      },
      "source": [
        "Just as you might've expected, the tensors come out with different values.\n",
        "\n",
        "But what if you wanted to created two random tensors with the *same* values.\n",
        "\n",
        "As in, the tensors would still contain random values but they would be of the same flavour.\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that flavours the randomness.\n",
        "\n",
        "Let's try it out by creating some more *flavoured* random tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWbjP73pG-vC",
        "outputId": "0db3142d-2abf-4848-be05-baec3540f43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor a:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor b:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor a equal Tensor b? (anywhere)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_a = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_b = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor a:\\n{random_a}\\n\")\n",
        "print(f\"Tensor b:\\n{random_b}\\n\")\n",
        "print(f\"Does Tensor a equal Tensor b? (anywhere)\")\n",
        "random_a == random_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTXOscrie4oI"
      },
      "source": [
        "## Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
        "\n",
        "Your computer might have one.\n",
        "\n",
        "If so, you should look to use it whenever you can to train neural networks because chances are it'll speed up the training time dramatically.\n",
        "\n",
        "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PPFq-sUG-sh",
        "outputId": "fcc8e59c-bb04-48b5-9d5d-c4ac6b383b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGColwYPgbs4"
      },
      "source": [
        "\n",
        "\n",
        "###  Getting PyTorch to run on the GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
        "\n",
        "To do so, you can use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "Rather than talk about it, let's try it out.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9odkr_Le6_j",
        "outputId": "28384c6f-158b-4b41-e603-4f1c26d89029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Sw2IC6vYe69c",
        "outputId": "e0a85608-8d38-437f-dbaa-0f400a76f87f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Np6K_8G-qI",
        "outputId": "675821e2-506a-4192-eeb3-22a611548458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlsHBE-ihqcu"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output `\"cpu\"`, our PyTorch code will stick with the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do *much* faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYVhh4aGiNr0"
      },
      "source": [
        "---\n",
        "\n",
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "---\n",
        "You can put tensors (and models, we'll see this later) on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj-xB5WmFPp7",
        "outputId": "0a986e82-c1b7-4288-e4d2-6e2625c2e4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ],
      "source": [
        "# default is on cpu\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(tensor, tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr478ZKXhrxc",
        "outputId": "a5b6f2e5-cab5-467b-c09d-b82ac89df303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move tensor to gpu if available\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcFeJma0jZT5"
      },
      "source": [
        "### 4. Moving tensors back to the CPU\n",
        "\n",
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw7HvIRbhruy",
        "outputId": "f44fe328-2553-4ed4-ddba-d50073367f30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# No NumPy on gpu\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WOW2fyOhrsV",
        "outputId": "bf5285f3-6f1c-45f1-dd02-144159b52c46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To fix gpu tensor woth numpy issue can set it on cpu\n",
        "tensor_on_gpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f56SsCZLLkg4"
      },
      "source": [
        "**Checking how many dimentions - `.ndim`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbU8VCUGNm9z"
      },
      "source": [
        "**Tensor size - `.shape` or `size()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWajjdtorMWg"
      },
      "source": [
        "**Synthax for creating 'random_image_tensor' = `torch.rand(size=(3, 224, 224))`\n",
        "          num of color channels can be in front or in the back**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMRTEVbhuZXK"
      },
      "source": [
        "**Tensor data type - `.dtype` if not specified always float**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_UG474q0HJv"
      },
      "source": [
        "**Creating tensors with the size of another tensor - `tensor.[ones/zeros/rand]_like(input)`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AQtrQDOyapz"
      },
      "source": [
        "**Getting device from tensor - `.device`**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5wD2ZPQWej5cfU/NcMELz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}